---
title: ELFK
description: docker 安装 ELFK
sidebar:
  order: 8
---
```yaml
# 网桥 -> 方便相互通讯
networks:
  elkf:

services:
  elasticsearch:
    image: elasticsearch:7.14.1
    container_name: elkf_elasticsearch         # 容器名为'elkf_elasticsearch'
    hostname: elkf_elasticsearch
    restart: unless-stopped                   # 指定容器退出后的重启策略为始终重启，但是不考虑在Docker守护进程启动时就已经停止了的容器
    volumes:                                  # 数据卷挂载路径设置,将本机目录映射到容器目录
      - "/application/middleware/elkf/elasticsearch/data:/usr/share/elasticsearch/data"
      - "/application/middleware/elkf/elasticsearch/logs:/usr/share/elasticsearch/logs"
      - "/application/middleware/elkf/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml"
#      - "/application/middleware/elkf/elasticsearch/config/jvm.options:/usr/share/elasticsearch/config/jvm.options"
    environment:                              # 设置环境变量,相当于docker run命令中的-e
      TZ: Asia/Shanghai
      LANG: en_US.UTF-8
      TAKE_FILE_OWNERSHIP: "true"  # 权限
      discovery.type: single-node
      ES_JAVA_OPTS: "-Xmx512m -Xms512m"
      ELASTIC_PASSWORD: "123456" # elastic账号密码
    ports:
      - "9200:9200"
      - "9300:9300"
    networks:
      - elkf

  kibana:
    image: kibana:7.14.1
    container_name: elkf_kibana
    hostname: elkf_kibana
    restart: unless-stopped
    volumes:
      - "/application/middleware/elkf/kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml"
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
    links:
      - elasticsearch
    networks:
      - elkf

  logstash:
    image: logstash:7.14.1
    container_name: elkf_logstash
    hostname: elkf_logstash
    restart: unless-stopped
    environment:
      LS_JAVA_OPTS: "-Xmx512m -Xms512m"
    volumes:
      - "/application/middleware/elkf/logstash/data:/usr/share/logstash/data"
      - "/application/middleware/elkf/logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml"
#      - "/application/middleware/elkf/logstash/config/logstash.conf:/usr/share/logstash/config/logstash.conf"
      - "/application/middleware/elkf/logstash/config/test:/usr/share/logstash/config/test"
#    command: logstash -f /usr/share/logstash/config/logstash.conf    # 指定logstash启动时使用的配置文件 - 指定单个文件
    command: logstash -f /usr/share/logstash/config/test       # 指定logstash启动时使用的配置文件 - 指定目录夹（系统会自动读取文件夹下所有配置文件，并在内存中整合）
    ports:
      - "9600:9600"
#      - "10001-10010:10001-10010"
      - "5044:5044"
    depends_on:
      - elasticsearch
    networks:
      - elkf

  filebeat:
    image: filebeat:7.14.1
    container_name: elkf_filebeat
    hostname: elkf_filebeat
    restart: unless-stopped                   # 指定容器退出后的重启策略为始终重启，但是不考虑在Docker守护进程启动时就已经停止了的容器
    volumes:                                  # 数据卷挂载路径设置,将本机目录映射到容器目录
      - "/application/middleware/elkf/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml"
      - "/application/middleware/elkf/filebeat/logs:/usr/share/filebeat/logs"
      - "/application/middleware/elkf/filebeat/my-log:/usr/share/filebeat/my-log"
    environment:          # 设置环境变量,相当于docker run命令中的-e
      TZ: Asia/Shanghai
      LANG: en_US.UTF-8
    depends_on:
      - elasticsearch
      - logstash
    networks:
      - elkf
```
import { LinkCard } from '@astrojs/starlight/components';

<LinkCard title="使用文档" href="../readme" />

## 配置文件

### elasticsearch
> elasticsearch.yml
```yaml
cluster.name: "docker-cluster"
network.host: 0.0.0.0
http.port: 9200
# 开启es跨域
http.cors.enabled: true
http.cors.allow-origin: "*"
http.cors.allow-headers: Authorization
# 开启安全控制
xpack.security.enabled: true
xpack.security.transport.ssl.enabled: true

```
> jvm.options
```properties
## JVM configuration

################################################################
## IMPORTANT: JVM heap size
################################################################
##
## You should always set the min and max JVM heap
## size to the same value. For example, to set
## the heap to 4 GB, set:
##
## -Xms4g
## -Xmx4g
##
## See https://www.elastic.co/guide/en/elasticsearch/reference/current/heap-size.html
## for more information
##
################################################################

# Xms represents the initial size of total heap space
# Xmx represents the maximum size of total heap space

-Xms1g
-Xmx1g

################################################################
## Expert settings
################################################################
##
## All settings below this section are considered
## expert settings. Don't tamper with them unless
## you understand what you are doing
##
################################################################

## GC configuration
8-13:-XX:+UseConcMarkSweepGC
8-13:-XX:CMSInitiatingOccupancyFraction=75
8-13:-XX:+UseCMSInitiatingOccupancyOnly

## G1GC Configuration
# NOTE: G1 GC is only supported on JDK version 10 or later
# to use G1GC, uncomment the next two lines and update the version on the
# following three lines to your version of the JDK
# 10-13:-XX:-UseConcMarkSweepGC
# 10-13:-XX:-UseCMSInitiatingOccupancyOnly
14-:-XX:+UseG1GC
14-:-XX:G1ReservePercent=25
14-:-XX:InitiatingHeapOccupancyPercent=30

## JVM temporary directory
-Djava.io.tmpdir=${ES_TMPDIR}

## heap dumps

# generate a heap dump when an allocation from the Java heap fails
# heap dumps are created in the working directory of the JVM
-XX:+HeapDumpOnOutOfMemoryError

# specify an alternative path for heap dumps; ensure the directory exists and
# has sufficient space
-XX:HeapDumpPath=data

# specify an alternative path for JVM fatal error logs
-XX:ErrorFile=logs/hs_err_pid%p.log

## JDK 8 GC logging
8:-XX:+PrintGCDetails
8:-XX:+PrintGCDateStamps
8:-XX:+PrintTenuringDistribution
8:-XX:+PrintGCApplicationStoppedTime
8:-Xloggc:logs/gc.log
8:-XX:+UseGCLogFileRotation
8:-XX:NumberOfGCLogFiles=32
8:-XX:GCLogFileSize=64m

# JDK 9+ GC logging
9-:-Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m

```
### kibana
> kibana.yml
```yaml
#
# ** THIS IS AN AUTO-GENERATED FILE **
#

# Default Kibana configuration for docker target

server.name: kibana
server.host: "0.0.0.0"
server.publicBaseUrl: "http://ekf_kibana:5601"  # 这里地址改为你访问kibana的地址，不能以 / 结尾
elasticsearch.hosts: [ "http://elkf_elasticsearch:9200" ] # 使用容器的hostname或者使用自己的ip
xpack.monitoring.ui.container.elasticsearch.enabled: true
elasticsearch.username: "elastic"  # es账号
elasticsearch.password: "123456"   # es密码
i18n.locale: zh-CN # 中文

```
### logstash
> logstash.conf
```yaml
# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.

input {

    tcp {
        mode => "server"
        host => "0.0.0.0"
        port => 5044
        codec => json{
          charset=>"UTF-8"
        }
    }

    # ex: 创建2个微服务demo，建立2个不同的输入，将两个服务的日志分别输入到不同的索引中

    tcp {
        mode => "server"
        host => "0.0.0.0"         # 允许任意主机发送日志
        type => "java_demo_log_1" # 设定type以区分每个输入源
        port => 10001
        codec => json_lines       # 数据格式
    }

    tcp {
        mode => "server"
        host => "0.0.0.0"
        type => "java_demo_log_2"
        port => 10002
        codec => json_lines
    }

}

output {

    # For detail config for elasticsearch as output,
    # See: https://www.elastic.co/guide/en/logstash/current/plugins-outputs-elasticsearch.html

    # elasticsearch {
    #     hosts => ["http://elkf_elasticsearch:9200"]
    #     #index => "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
    #     index => "demo-log-%{+YYYY.MM.dd}"
    #     #user => "elastic"
    #     #password => "changeme"
    # }

    stdout{
        codec => rubydebug
    }

    if [type] == "java_demo_log_1" {
        elasticsearch {
            action => "index"                            # 输出时创建映射
            hosts  => "http://elkf_elasticsearch:9200"        # ElasticSearch地址和端口
            index  => "java_demo_log_1-%{+YYYY.MM.dd}"   # 指定索引名-按天
            codec  => "json"
        }
    }

    if [type] == "java_demo_log_2" {
        elasticsearch {
            action => "index"
            hosts  => "http://elkf_elasticsearch:9200"
            index  => "java_demo_log_2-%{+YYYY.MM.dd}"
            codec  => "json"
        }
    }

}

```

> logstash.yml
```yaml
http.host: "0.0.0.0"
xpack.monitoring.enabled: true
xpack.monitoring.elasticsearch.hosts: [ "http://elkf_elasticsearch:9200" ]
xpack.monitoring.elasticsearch.username: "elastic"
xpack.monitoring.elasticsearch.password: "123456"

 ```
> demo.conf
```yaml
# 日志输入
input {
    beats {
        port => 5044
    }
}


filter {
    # 让无结构的日志内容结构化
    grok {
        match => { "message" => "(?<datetime>\d{4}-\d{2}-\d{2}\s\d{2}:\d{2}:\d{2}\.\d{3})\s+(?<level>\w+)\s+\d+\s+-+\s\[[^\[\]]+\]\s+(?<class>\S+)\s+:(?<msg>.*)" }
    }

    mutate {
        # 过滤字段
        remove_field => ["LOG_MAX_HISTORY_DAY", "LOG_HOME", "APP_NAME"]
        remove_field => ["@version", "_score", "port", "level_value", "tags", "_type", "host"]
        remove_field => ["agent", "@timestamp", "@timestamp", "ecs", "input", "log"]
    }
}

# 日志输出-控制台
output {
    stdout{
        codec => rubydebug
    }
}

# 日志输出-es
output {
    elasticsearch {
        action => "index"                       # 输出时创建映射
        hosts  => "http://elkf_elasticsearch:9200"   # ES地址和端口
        user => "elastic"                       # ES用户名
        password => "123456"                    # ES密码
        index  => "demo-%{+YYYY.MM.dd}"         # 指定索引名-按天
        codec  => "json"
    }
}

```
### filebeat
> filebeta.yml
```yaml
# 可参考 https://www.elastic.co/guide/en/beats/filebeat/7.14/filebeat-reference-yml.html

# 收集系统日志
filebeat:
  inputs:
    - type: log
      enabled: true
      encoding: utf-8
      paths:
        - /usr/share/filebeat/my-log/demo*.log # 系统日志路径
      tags: [ "demo" ]
      # java多行日志合并
      multiline:
        pattern: '^\d{4}\-\d{2}\-\d{2}\s\d{2}:\d{2}:\d{2}' # 匹配的正则 不是以 2021-10-01 12:00:00 格式开头的将合并到上一行
        negate: true                                       # 是否反向匹配
        match: after                                       # 取值为 after 则放到上一行之后，取值为 before 则放到下一行之前
        timeout: 3s


# 输出到logstash
output.logstash:
  hosts: ["elkf_logstash:5044"] # logstash服务器地址，可以有多个，以逗号","隔开

```
